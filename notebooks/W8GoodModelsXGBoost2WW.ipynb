{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CalculatedContent/xgboost2ww/blob/main/notebooks/W8GoodModelsXGBoost2WW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "StH5YMSAbUak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# xgboost2ww Experiment (100 random models)\n",
        "\n",
        "This starter notebook trains 100 random XGBoost models and evaluates the result.  \n",
        "\n",
        "It shows you how to:\n",
        "1. Pick a “good” XGBoost model using **training-only cross-validation**.\n",
        "2. Evaluate it on a **true holdout test set** (never used in CV or OOF).\n",
        "3. Use **xgboost2ww.convert()** to build tiny PyTorch layers for the **W** (W7 default)\n",
        "4. Run **WeightWatcher** to estimate:\n",
        "   - **α (alpha)**: heavy-tail exponent estimate\n",
        "   - **traps**: randomization spikes proxy (WeightWatcher diagnostic)\n",
        "\n",
        "**Note:** For an initial evaluation, you do **not** need `detX=True` in WeightWatcher.\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "### User can set:\n",
        "\n",
        "Matrix = \"W7\"\n",
        "\n",
        "TARGET_DATASETS = 100"
      ],
      "metadata": {
        "id": "r79T_pncTmsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Pick Matrix W1 | W2 | W7 | W8\n",
        "MATRIX = \"W8\"\n",
        "\n",
        "# Starter run size\n",
        "TARGET_DATASETS = 100\n",
        "\n"
      ],
      "metadata": {
        "id": "cqGv-u-BVdP-"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up folder on Google Drive to save final results[link text](https://)"
      ],
      "metadata": {
        "id": "HAhyaLN1i9gH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount(\"/content/drive\", force_remount=False)\n",
        "\n",
        "# Create output folder\n",
        "GDRIVE_DIR = \"/content/drive/MyDrive/xgboost2ww_runs\"\n",
        "os.makedirs(GDRIVE_DIR, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaLll30p_8sT",
        "outputId": "6bd663f3-9336-44ad-d8bf-b11b76057a54"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies"
      ],
      "metadata": {
        "id": "xN8kWgV1jAVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install \"pandas==2.2.2\" xgboost weightwatcher scikit-learn openml scipy pyarrow\n",
        "!apt-get -qq update && apt-get -qq install -y git\n",
        "\n",
        "# Clone + install xgboost2ww (public repo)\n",
        "!pip install xgboost2ww\n",
        "\n",
        "import xgboost2ww\n",
        "print(\"xgboost2ww loaded from:\", getattr(xgboost2ww, \"__file__\", None))\n",
        "\n",
        "from xgboost2ww import convert\n",
        "print(\"Imported xgboost2ww.convert OK\")"
      ],
      "metadata": {
        "id": "uxFwluf9ToUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c17146-d25c-475a-f486-92c38b15d9a7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Requirement already satisfied: xgboost2ww in /usr/local/lib/python3.12/dist-packages (0.1.0)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from xgboost2ww) (2.0.2)\n",
            "Requirement already satisfied: xgboost>=1.7 in /usr/local/lib/python3.12/dist-packages (from xgboost2ww) (3.2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from xgboost2ww) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->xgboost2ww) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->xgboost2ww) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->xgboost2ww) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost>=1.7->xgboost2ww) (2.27.5)\n",
            "xgboost2ww loaded from: /usr/local/lib/python3.12/dist-packages/xgboost2ww/__init__.py\n",
            "Imported xgboost2ww.convert OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and settings\n",
        "\n",
        "We’ll run a small starter experiment over a handful of OpenML binary datasets.\n",
        "\n",
        "Key settings:\n",
        "- `TARGET_DATASETS`: how many datasets to run (starter: 10)\n",
        "- `NFOLDS`: OOF folds for xgboost2ww matrices\n",
        "- `T_TRAJ`: how many trajectory points along boosting to sample"
      ],
      "metadata": {
        "id": "LrWB074kTonQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings, time\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import openml\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "import torch\n",
        "import weightwatcher as ww\n",
        "\n",
        "# Reproducibility\n",
        "RNG = 0\n",
        "rng = np.random.default_rng(RNG)\n",
        "\n",
        "\n",
        "# Train/test split (true holdout)\n",
        "TEST_SIZE = 0.20\n",
        "\n",
        "# OOF matrix construction\n",
        "NFOLDS = 5\n",
        "T_TRAJ = 160\n",
        "\n",
        "# Data cap + safety guard\n",
        "MAX_OPENML_ROWS = 60000\n",
        "MAX_FEATURES_GUARD = 50_000\n",
        "\n",
        "# “Good model” selection (training-only CV)\n",
        "GOOD_TRIALS = 5\n",
        "CV_MAX_ROUNDS = 3000\n",
        "CV_EARLY_STOP = 150\n",
        "MIN_GOOD_TEST_ACC = 0.75\n",
        "\n",
        "# OpenML suites to pull datasets from\n",
        "SUITE_IDS = [14, 99, 225]"
      ],
      "metadata": {
        "id": "VaeRDLyaTovg"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: GPU detection for XGBoost\n",
        "\n",
        "If a GPU is available, we’ll use XGBoost’s `gpu_hist` for faster training.\n",
        "If not, we fall back to CPU `hist`."
      ],
      "metadata": {
        "id": "fa_CgTaYTo3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xgb_gpu_available() -> bool:\n",
        "    try:\n",
        "        Xtmp = np.random.randn(256, 8).astype(np.float32)\n",
        "        ytmp = (Xtmp[:, 0] > 0).astype(np.int32)\n",
        "        dtmp = xgb.DMatrix(Xtmp, label=ytmp)\n",
        "        params = dict(\n",
        "            objective=\"binary:logistic\",\n",
        "            eval_metric=\"logloss\",\n",
        "            tree_method=\"gpu_hist\",\n",
        "            predictor=\"gpu_predictor\",\n",
        "            max_depth=2,\n",
        "            learning_rate=0.2,\n",
        "            seed=RNG,\n",
        "        )\n",
        "        _ = xgb.train(params=params, dtrain=dtmp, num_boost_round=5, verbose_eval=False)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "USE_GPU = xgb_gpu_available()\n",
        "print(\"XGBoost GPU available:\", USE_GPU)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-34rS7OATpAB",
        "outputId": "e7f07d99-132c-407a-f688-2f65af05e2e6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost GPU available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "## Load OpenML binary datasets (with preprocessing)\n",
        "\n",
        "We:\n",
        "- Keep only **binary** classification datasets\n",
        "- One-hot encode categorical features\n",
        "- Impute missing values\n",
        "- Optionally cap dataset size (`MAX_OPENML_ROWS`) for speed\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Qnm_xfUZTzwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def factorize_binary(y_raw):\n",
        "    y_codes, uniques = pd.factorize(y_raw)\n",
        "    if len(uniques) != 2:\n",
        "        return None\n",
        "    return y_codes.astype(int)\n",
        "\n",
        "def make_preprocessor(Xdf: pd.DataFrame):\n",
        "    cat_cols = Xdf.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
        "    num_cols = [c for c in Xdf.columns if c not in cat_cols]\n",
        "    transformers = []\n",
        "    if len(num_cols):\n",
        "        transformers.append((\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols))\n",
        "    if len(cat_cols):\n",
        "        transformers.append((\"cat\", Pipeline([\n",
        "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "            (\"oh\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
        "        ]), cat_cols))\n",
        "    if not transformers:\n",
        "        raise ValueError(\"no usable columns\")\n",
        "    return ColumnTransformer(transformers=transformers, remainder=\"drop\", sparse_threshold=0.3)\n",
        "\n",
        "def enumerate_openml_dataset_ids_from_suites(suite_ids):\n",
        "    ids, seen = [], set()\n",
        "    for sid in suite_ids:\n",
        "        suite = openml.study.get_suite(sid)\n",
        "        for did in suite.data:\n",
        "            did = int(did)\n",
        "            if did not in seen:\n",
        "                ids.append(did)\n",
        "                seen.add(did)\n",
        "    return ids\n",
        "\n",
        "def load_openml_dataset_by_id(did: int):\n",
        "    ds = openml.datasets.get_dataset(did)\n",
        "    target = ds.default_target_attribute\n",
        "    Xdf, y_raw, _, _ = ds.get_data(dataset_format=\"dataframe\", target=target)\n",
        "\n",
        "    y = factorize_binary(y_raw)\n",
        "    if y is None:\n",
        "        return None\n",
        "\n",
        "    if MAX_OPENML_ROWS is not None and len(Xdf) > MAX_OPENML_ROWS:\n",
        "        take = rng.choice(len(Xdf), size=MAX_OPENML_ROWS, replace=False)\n",
        "        Xdf = Xdf.iloc[take].reset_index(drop=True)\n",
        "        y = y[take]\n",
        "\n",
        "    pre = make_preprocessor(Xdf)\n",
        "    X = pre.fit_transform(Xdf)\n",
        "    return X, y.astype(int), ds.name, did"
      ],
      "metadata": {
        "id": "xLaWw5d_Tz3P"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pick a “good” XGBoost model using training-only CV\n",
        "\n",
        "For each dataset:\n",
        "1. Split into **train/test**\n",
        "2. Run CV on the **train only** set to pick hyperparameters + early-stopping rounds\n",
        "3. Train a final model on train\n",
        "4. Evaluate once on the holdout test set\n",
        "\n",
        "We keep only datasets where the holdout test accuracy is at least `MIN_GOOD_TEST_ACC`."
      ],
      "metadata": {
        "id": "XcOM6Ow-Tz_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pick_good_params_via_cv(Xtr, ytr, nfold=5, *, dataset_id: int):\n",
        "    dtrain = xgb.DMatrix(Xtr, label=ytr)\n",
        "    local_rng = np.random.default_rng(RNG + int(dataset_id))  # stable across runs\n",
        "\n",
        "    best = None\n",
        "    best_score = np.inf\n",
        "\n",
        "    for _ in range(GOOD_TRIALS):\n",
        "        params = dict(\n",
        "            objective=\"binary:logistic\",\n",
        "            eval_metric=\"logloss\",\n",
        "            tree_method=\"hist\",\n",
        "            seed=RNG,\n",
        "            learning_rate=float(10 ** local_rng.uniform(-2.0, -0.6)),   # 0.01..0.25\n",
        "            max_depth=int(local_rng.integers(2, 7)),\n",
        "            min_child_weight=float(10 ** local_rng.uniform(0.0, 2.0)),  # 1..100\n",
        "            subsample=float(local_rng.uniform(0.6, 0.9)),\n",
        "            colsample_bytree=float(local_rng.uniform(0.6, 0.9)),\n",
        "            reg_lambda=float(10 ** local_rng.uniform(0.0, 2.0)),        # 1..100\n",
        "            gamma=float(local_rng.uniform(0.0, 0.5)),\n",
        "        )\n",
        "        if USE_GPU:\n",
        "            params[\"tree_method\"] = \"gpu_hist\"\n",
        "            params[\"predictor\"] = \"gpu_predictor\"\n",
        "\n",
        "        cv = xgb.cv(\n",
        "            params=params,\n",
        "            dtrain=dtrain,\n",
        "            num_boost_round=CV_MAX_ROUNDS,\n",
        "            nfold=nfold,\n",
        "            stratified=True,\n",
        "            early_stopping_rounds=CV_EARLY_STOP,\n",
        "            seed=RNG,\n",
        "            verbose_eval=False,\n",
        "        )\n",
        "\n",
        "        score = float(cv[\"test-logloss-mean\"].iloc[-1])\n",
        "        rounds = int(len(cv))\n",
        "        if score < best_score:\n",
        "            best_score = score\n",
        "            best = (params, rounds, score)\n",
        "\n",
        "    return best  # (params, rounds, cv_logloss)\n",
        "\n",
        "def train_eval_fulltrain(Xtr, ytr, Xte, yte, params, rounds):\n",
        "    dtr = xgb.DMatrix(Xtr, label=ytr)\n",
        "    dte = xgb.DMatrix(Xte, label=yte)\n",
        "\n",
        "    bst = xgb.train(params=params, dtrain=dtr, num_boost_round=rounds, verbose_eval=False)\n",
        "\n",
        "    m_tr = bst.predict(dtr, output_margin=True).astype(np.float32)\n",
        "    p_tr = 1.0 / (1.0 + np.exp(-m_tr))\n",
        "    train_acc = float(accuracy_score(ytr, (p_tr >= 0.5).astype(int)))\n",
        "\n",
        "    m_te = bst.predict(dte, output_margin=True).astype(np.float32)\n",
        "    p_te = 1.0 / (1.0 + np.exp(-m_te))\n",
        "    test_acc = float(accuracy_score(yte, (p_te >= 0.5).astype(int)))\n",
        "    test_loss = float(log_loss(yte, np.vstack([1 - p_te, p_te]).T, labels=[0, 1]))\n",
        "\n",
        "    return train_acc, test_acc, test_loss, bst"
      ],
      "metadata": {
        "id": "qxYlKLUpT0H9"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WeightWatcher helper\n",
        "\n",
        "We use WeightWatcher on the PyTorch layer returned by `xgboost2ww.convert()`.\n",
        "\n",
        "For a first pass, we run:\n",
        "\n",
        "`watcher.analyze(randomize=True, ERG=True, plot=False)`\n",
        "\n",
        "No `detX=True` needed for initial evaluation."
      ],
      "metadata": {
        "id": "D2Vj0TwCT0Qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ww_metrics_from_layer(layer):\n",
        "    watcher = ww.WeightWatcher(model=layer)\n",
        "    details_df = watcher.analyze(randomize=True, ERG=True, plot=False)  # starter: no detX\n",
        "    alpha = float(details_df[\"alpha\"].iloc[0]) if \"alpha\" in details_df.columns else np.nan\n",
        "    traps = float(details_df[\"num_traps\"].iloc[0]) if \"rand_num_spikes\" in details_df.columns else np.nan\n",
        "    ERG_gap = float(details_df[\"ERG_gap\"].iloc[0]) if \"ERG_gap\" in details_df.columns else np.nan\n",
        "    return alpha, traps, ERG_gap"
      ],
      "metadata": {
        "id": "snaQwsuwT0Xy"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the experiment (first 10 datasets)\n",
        "\n",
        "For each dataset, we compute α/traps for **W**.\n",
        "\n",
        "Key reproducibility detail:\n",
        "- We pass `train_params=good_params` and `num_boost_round=good_rounds` into `convert()`\n",
        "- That ensures the fold-training used to compute OOF increments matches the chosen model configuration."
      ],
      "metadata": {
        "id": "-sSz-5yaUCzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# MAIN LOOP — Compute W7|W8|... ONLY using xgboost2ww.convert()\n",
        "# Memory-safe version:\n",
        "#   - keep sparse when possible (XGBoost supports CSR)\n",
        "#   - avoid densifying big one-hot matrices\n",
        "#   - use float32\n",
        "#   - hard guards + cleanup\n",
        "# ============================================================\n",
        "\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "rows = []\n",
        "kept = 0\n",
        "\n",
        "# If you ever densify, this is the real RAM killer.\n",
        "# 2e8 float32 ~ 0.8GB. float64 would be ~1.6GB.\n",
        "MAX_DENSE_ELEMENTS = int(2e8)\n",
        "\n",
        "dataset_ids = enumerate_openml_dataset_ids_from_suites(SUITE_IDS)\n",
        "t0 = time.time()\n",
        "\n",
        "for did in dataset_ids:\n",
        "    if kept >= TARGET_DATASETS:\n",
        "        break\n",
        "\n",
        "    loaded = load_openml_dataset_by_id(int(did))\n",
        "    if loaded is None:\n",
        "        continue\n",
        "\n",
        "    X, y, name, did_loaded = loaded\n",
        "\n",
        "    # ---- Feature guard (still useful, but not sufficient alone)\n",
        "    if int(X.shape[1]) > MAX_FEATURES_GUARD:\n",
        "        continue\n",
        "\n",
        "    # -----------------------------\n",
        "    # True holdout split\n",
        "    # -----------------------------\n",
        "    tr_idx, te_idx = train_test_split(\n",
        "        np.arange(len(y)),\n",
        "        test_size=TEST_SIZE,\n",
        "        random_state=RNG,\n",
        "        stratify=y\n",
        "    )\n",
        "\n",
        "    Xtr = X[tr_idx]\n",
        "    Xte = X[te_idx]\n",
        "    ytr = y[tr_idx]\n",
        "    yte = y[te_idx]\n",
        "\n",
        "    # -----------------------------\n",
        "    # Keep sparse if sparse; cast to float32 if dense\n",
        "    # -----------------------------\n",
        "    is_sparse = hasattr(Xtr, \"tocoo\")  # works for scipy sparse matrices\n",
        "\n",
        "    if not is_sparse:\n",
        "        # Dense path: force 2D arrays and float32\n",
        "        Xtr = np.asarray(Xtr, dtype=np.float32)\n",
        "        Xte = np.asarray(Xte, dtype=np.float32)\n",
        "\n",
        "        if Xtr.ndim != 2:\n",
        "            print(\"SKIP: unexpected Xtr shape:\", getattr(Xtr, \"shape\", None))\n",
        "            continue\n",
        "    else:\n",
        "        # Sparse path: DO NOT densify for CV/training\n",
        "        # Convert to CSR once (fast row slicing + DMatrix friendly)\n",
        "        Xtr = Xtr.tocsr()\n",
        "        Xte = Xte.tocsr()\n",
        "\n",
        "        # OPTIONAL: you may also enforce float32 data in CSR\n",
        "        # (scipy sparse supports astype efficiently)\n",
        "        try:\n",
        "            Xtr = Xtr.astype(np.float32)\n",
        "            Xte = Xte.astype(np.float32)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # HARD guard: if someone later tries to densify, estimate cost\n",
        "        dense_cost = int(Xtr.shape[0]) * int(Xtr.shape[1])\n",
        "        if dense_cost > MAX_DENSE_ELEMENTS:\n",
        "            # We can still train XGBoost on sparse,\n",
        "            # but convert() might require dense -> likely OOM.\n",
        "            # Safer to skip early unless you have a sparse-aware convert().\n",
        "            print(\n",
        "                f\"SKIP: sparse would densify too big: \"\n",
        "                f\"n_train={Xtr.shape[0]}, d={Xtr.shape[1]}, \"\n",
        "                f\"elements={dense_cost:,}\"\n",
        "            )\n",
        "            # cleanup\n",
        "            del X, y, Xtr, Xte, ytr, yte\n",
        "            gc.collect()\n",
        "            continue\n",
        "\n",
        "    # -----------------------------\n",
        "    # Select \"good\" hyperparameters (train-only CV)\n",
        "    # -----------------------------\n",
        "    good_params, good_rounds, good_cv_logloss = pick_good_params_via_cv(\n",
        "        Xtr, ytr, nfold=NFOLDS, dataset_id=int(did_loaded)\n",
        "    )\n",
        "\n",
        "    # Train final model and evaluate on holdout\n",
        "    good_train_acc, good_test_acc, good_test_loss, bst = train_eval_fulltrain(\n",
        "        Xtr, ytr, Xte, yte, good_params, good_rounds\n",
        "    )\n",
        "\n",
        "    if good_test_acc < MIN_GOOD_TEST_ACC:\n",
        "        # cleanup\n",
        "        del bst, X, y, Xtr, Xte, ytr, yte\n",
        "        gc.collect()\n",
        "        continue\n",
        "\n",
        "    # ============================================================\n",
        "    # Compute W using xgboost2ww.convert()\n",
        "    # ============================================================\n",
        "    try:\n",
        "        # If convert() can accept CSR directly, great.\n",
        "        # If it cannot, this will throw and we skip cleanly.\n",
        "        layer_W = convert(\n",
        "            model=bst,\n",
        "            data=Xtr,\n",
        "            labels=ytr,\n",
        "            W=MATRIX,\n",
        "            nfolds=NFOLDS,\n",
        "            t_points=T_TRAJ,\n",
        "            random_state=RNG,\n",
        "            train_params=good_params,\n",
        "            num_boost_round=good_rounds,\n",
        "            multiclass=\"error\",\n",
        "            return_type=\"torch\",\n",
        "            verbose=False,\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(\"SKIP during convert():\", type(e).__name__, e)\n",
        "        # cleanup\n",
        "        del bst, X, y, Xtr, Xte, ytr, yte\n",
        "        gc.collect()\n",
        "        continue\n",
        "\n",
        "    # WeightWatcher structural diagnostics\n",
        "    alpha_W, traps_W, ERG_gap_W = ww_metrics_from_layer(layer_W)\n",
        "\n",
        "    rows.append(dict(\n",
        "        openml_id=int(did_loaded),\n",
        "        dataset=name,\n",
        "        n_rows_total=int(X.shape[0]),\n",
        "        n_train=int(Xtr.shape[0]),\n",
        "        n_test=int(Xte.shape[0]),\n",
        "        n_features=int(X.shape[1]),\n",
        "        rounds=int(good_rounds),\n",
        "        cv_logloss=float(good_cv_logloss),\n",
        "        good_train_acc=float(good_train_acc),\n",
        "        good_test_acc=float(good_test_acc),\n",
        "        good_test_loss=float(good_test_loss),\n",
        "        alpha_W=float(alpha_W),\n",
        "        traps_W=float(traps_W),\n",
        "        ERG_gap_W=float(ERG_gap_W),\n",
        "    ))\n",
        "\n",
        "    kept += 1\n",
        "    elapsed = (time.time() - t0) / 60.0\n",
        "\n",
        "    print(\n",
        "        f\"[{kept}/{TARGET_DATASETS}] {name} (OpenML {did_loaded}) \"\n",
        "        f\"| train/test={good_train_acc:.3f}/{good_test_acc:.3f} \"\n",
        "        f\"| α(W)={alpha_W:.2f} traps(W)={traps_W:.1f} \"\n",
        "        f\"| elapsed={elapsed:.1f} min\",\n",
        "        flush=True\n",
        "    )\n",
        "\n",
        "    # cleanup big objects each iteration\n",
        "    del bst, layer_W, X, y, Xtr, Xte, ytr, yte\n",
        "    gc.collect()\n",
        "\n",
        "df_good = pd.DataFrame(rows)\n",
        "\n",
        "print(f\"\\nDONE. datasets_kept={df_good['openml_id'].nunique()} rows={len(df_good)}\")\n",
        "df_good"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP_ZQ6JaUC6k",
        "outputId": "e4766bee-de1a-47c4-8051-f12025f72390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/100] kr-vs-kp (OpenML 3) | train/test=0.995/0.986 | α(W)=2.17 traps(W)=6.0 | elapsed=1.0 min\n",
            "[2/100] breast-w (OpenML 15) | train/test=0.977/0.979 | α(W)=1.90 traps(W)=6.0 | elapsed=1.1 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plots\n",
        "\n",
        "These quick plots help you sanity-check:\n",
        "- α values across datasets for the W (default) matrix\n",
        "- traps across datasets for the W (default) matrix\n",
        "- relationship between holdout accuracy and α(W)"
      ],
      "metadata": {
        "id": "9QWIYyx4UDBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if len(df_good) == 0:\n",
        "    print(\"No datasets kept. Try lowering MIN_GOOD_TEST_ACC.\")\n",
        "else:\n",
        "    x = np.arange(len(df_good))\n",
        "\n",
        "    # Alpha across datasets\n",
        "    plt.figure()\n",
        "    plt.plot(x, df_good[f\"alpha_W\"].values, label=MATRIX)\n",
        "    plt.xticks(x, df_good[\"dataset\"].values, rotation=90)\n",
        "    plt.ylabel(\"alpha\")\n",
        "    plt.title(\"Alpha across datasets\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Traps across datasets\n",
        "    plt.figure()\n",
        "    plt.plot(x, df_good[f\"traps_W\"].values, label=MATRIX)\n",
        "    plt.xticks(x, df_good[\"dataset\"].values, rotation=90)\n",
        "    plt.ylabel(\"traps (rand_num_spikes)\")\n",
        "    plt.title(\"Traps across datasets\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Holdout accuracy vs alpha(W)\n",
        "    plt.figure()\n",
        "    plt.scatter(df_good[\"good_test_acc\"].values, df_good[f\"alpha_W\"].values)\n",
        "    plt.xlabel(\"Holdout test accuracy\")\n",
        "    plt.ylabel(f\"alpha W\")\n",
        "    plt.title(f\"Holdout accuracy vs alpha{MATRIX}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Tn5W9wt-UDI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional structural diagnostics\n",
        "\n",
        "We now visualize the distribution of:\n",
        "\n",
        "- alpha(W)\n",
        "- traps(W)\n",
        "- ERG_gap(W)\n",
        "\n",
        "and examine the structural relationship between:\n",
        "\n",
        "alpha(W) and ERG_gap(W)\n",
        "\n",
        "This helps understand how scale invariance and the ERG determinant condition co-vary across models."
      ],
      "metadata": {
        "id": "yBDxqdlGuSCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "if len(df_good) == 0:\n",
        "    print(\"No results to plot.\")\n",
        "else:\n",
        "\n",
        "    # -------------------------\n",
        "    # Histogram: alpha_W\n",
        "    # -------------------------\n",
        "    plt.figure()\n",
        "    plt.hist(df_good[f\"alpha_W\"].dropna().values, bins=30)\n",
        "    plt.xlabel(f\"alpha_W\")\n",
        "    plt.ylabel(\"count\")\n",
        "    plt.title(f\"Histogram of alpha({MATRIX})\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # -------------------------\n",
        "    # Histogram: traps_W\n",
        "    # -------------------------\n",
        "    plt.figure()\n",
        "    plt.hist(df_good[f\"traps_W\"].dropna().values, bins=30)\n",
        "    plt.xlabel(f\"traps_W\")\n",
        "    plt.ylabel(\"count\")\n",
        "    plt.title(f\"Histogram of traps({MATRIX})\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # -------------------------\n",
        "    # Histogram: ERG_gap_W\n",
        "    # -------------------------\n",
        "    plt.figure()\n",
        "    plt.hist(df_good[f\"ERG_gap_W\"].dropna().values, bins=30)\n",
        "    plt.xlabel(f\"ERG_gap_W7\")\n",
        "    plt.ylabel(\"count\")\n",
        "    plt.title(f\"Histogram of ERG_gap({MATRIX})\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # -------------------------\n",
        "    # Scatter: alpha vs ERG_gap\n",
        "    # -------------------------\n",
        "    plt.figure()\n",
        "    plt.scatter(\n",
        "        df_good[f\"alpha_W\"].values,\n",
        "        df_good[f\"ERG_gap_W\"].values\n",
        "    )\n",
        "    plt.xlabel(f\"alpha_W\")\n",
        "    plt.ylabel(f\"ERG_gap_W\")\n",
        "    plt.title(f\"alpha({MATRIX}) vs ERG_gap({MATRIX})\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "pochOA_EuTH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Timestamped filename so we never overwrite runs\n",
        "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "RESULTS_FEATHER = os.path.join(GDRIVE_DIR, f\"{MATRIX}_results_{ts}.feather\")\n",
        "\n",
        "# Convert + save\n",
        "df_good = pd.DataFrame(rows)\n",
        "df_good.to_feather(RESULTS_FEATHER)\n",
        "\n",
        "print(f\"Saved {len(df_good)} rows to:\")\n",
        "print(RESULTS_FEATHER)\n",
        "\n",
        "df_good.head()"
      ],
      "metadata": {
        "id": "I2X26rEV-sHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RELOAD data fron Google Drive and plot"
      ],
      "metadata": {
        "id": "NU_jbZfph3aM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Load results from Google Drive + plot\n",
        "# (single Colab cell)\n",
        "# ============================================\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=False)\n",
        "\n",
        "GDRIVE_DIR = \"/content/drive/MyDrive/xgboost2ww_runs\"\n",
        "\n",
        "# Load the most recent results file by default\n",
        "files = sorted(glob.glob(os.path.join(GDRIVE_DIR, f\"{MATRIX}_results_*.feather\")))\n",
        "if not files:\n",
        "    raise FileNotFoundError(f\"No {MATRIX}_results_*.feather files found in {GDRIVE_DIR}\")\n",
        "\n",
        "RESULTS_FEATHER = files[-1]\n",
        "print(\"Loading:\", RESULTS_FEATHER)\n",
        "\n",
        "df = pd.read_feather(RESULTS_FEATHER)\n",
        "print(\"Rows:\", len(df), \"| Cols:\", len(df.columns))\n",
        "display(df.head(10))\n",
        "\n",
        "# ---- Basic cleanup / sort\n",
        "if \"test_acc\" in df.columns:\n",
        "    df = df.sort_values(\"test_acc\", ascending=False)\n",
        "elif \"good_test_acc\" in df.columns:\n",
        "    df = df.sort_values(\"good_test_acc\", ascending=False)\n",
        "\n",
        "# ---- Choose column names (supports both naming styles)\n",
        "alpha_col = f\"alpha_W\" if f\"alpha_W\" in df.columns else \"alpha\"\n",
        "traps_col = f\"traps_W\" if f\"traps_W\" in df.columns else \"traps\"\n",
        "test_col  = \"test_acc\" if \"test_acc\" in df.columns else (\"good_test_acc\" if \"good_test_acc\" in df.columns else None)\n",
        "train_col = \"train_acc\" if \"train_acc\" in df.columns else (\"good_train_acc\" if \"good_train_acc\" in df.columns else None)\n",
        "\n",
        "# ---- Plot 1: alpha_W7 distribution\n",
        "plt.figure()\n",
        "plt.hist(df[alpha_col].dropna().values, bins=30)\n",
        "plt.title(f\"Distribution of alpha({MATRIX})\")\n",
        "plt.xlabel(f\"alpha_W\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ---- Plot 2: traps_W distribution\n",
        "plt.figure()\n",
        "plt.hist(df[traps_col].dropna().values, bins=30)\n",
        "plt.title(f\"Distribution of traps({MATRIX})\")\n",
        "plt.xlabel(f\"traps_W\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ---- Plot 3: alpha(W) vs test accuracy\n",
        "if test_col is not None:\n",
        "    plt.figure()\n",
        "    plt.scatter(df[test_col].values, df[alpha_col].values)\n",
        "    plt.xlabel(test_col)\n",
        "    plt.ylabel(alpha_col)\n",
        "    plt.title(f\"alpha({MATRIX}) vs test accuracy\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---- Plot 4: train-test gap vs alpha(W) (if train exists)\n",
        "if test_col is not None and train_col is not None:\n",
        "    gap = df[train_col].values - df[test_col].values\n",
        "    plt.figure()\n",
        "    plt.scatter(gap, df[alpha_col].values)\n",
        "    plt.xlabel(\"train - test accuracy gap\")\n",
        "    plt.ylabel(alpha_col)\n",
        "    plt.title(f\"alpha(MATRIX) vs generalization gap\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---- Quick summary table\n",
        "summary_cols = [c for c in [\"dataset\",\"openml_id\",train_col,test_col,alpha_col,traps_col,\"rounds\"] if c and c in df.columns]\n",
        "print(\"Top 15 by test accuracy:\")\n",
        "display(df[summary_cols].head(15))"
      ],
      "metadata": {
        "id": "Mw510Uj9AxZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uat1bXniCYS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UNM-wQTy00S3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNQeUCm2SrVCQitZh2xx8iq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}